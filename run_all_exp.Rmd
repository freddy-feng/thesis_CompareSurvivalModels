---
title: "comparison"
author: "Yibin Feng"
date: '2022-06-13'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Dependencies
```{r}
# rm(list = ls())
library(tidyverse)

source("function_utility_exp.R")
source("function_evaluation.R")

select <- dplyr::select
```


# Experiment schedule

```{r}
exp.table <- data.frame(do.call(rbind, list(
  c("scenario0", "pCox", "scaled", "not_transformed"),
  c("scenario1", "pencal", "scaled", "not_transformed"),
  c("scenario1", "pCox", "scaled", "not_transformed"),
  c("scenario1", "MFPCCox", "scaled", "not_transformed"),
  c("scenario2", "pencal", "scaled", "not_transformed"),
  c("scenario2", "pCox", "scaled", "not_transformed"),
  c("scenario2", "MFPCCox", "scaled", "not_transformed")
  )))

colnames(exp.table) <- c(
  "scenario",
  "method",
  "scaling",
  "transformation"
)

exp.table <- exp.table %>%
  unite("model.name", c("scenario", "method", "scaling"), sep = "_", remove = FALSE)

exp.table$path.data <- NA

# Result paths
exp.table$path.model <- NA
exp.table$path.eval <- NA

print("----------------------------------------------------------------------")
print("Experiment schedule:")
print(exp.table)
print("----------------------------------------------------------------------")
```


# Set up



## Create splits

```{r}
# -----------------------------------------------------------------------------------
# Set experiment parameters here!
# -----------------------------------------------------------------------------------
n_fold <- 10 # Cross validation
seed <- 721 # Vary this for repeated CV
set_scenario <- "scenario1" # Determine how many longitudinal covariates to use
is_transformed <- "transformed"

baseline.covs <- c("AGE", "PTGENDER", "PTEDUCAT", "status.bl", "APOE4") # Baseline covariates
#baseline.covs <- c("AGE", "PTGENDER", "PTEDUCAT", "APOE4") # Baseline covariates
# -----------------------------------------------------------------------------------
# -----------------------------------------------------------------------------------

# -----------------------------------------------------------------------------------
# Load data
# -----------------------------------------------------------------------------------
# Contains two dataframes df.surv_preds and df.long_censored
path.data <- "adni_cleaned.RData"
load(path.data)

# may also reduce the number of columns here to reduce size
# Note: make sure data.surv and data.long are arranged by id and {id, age.fup}
# to ensure proper function with pencal package
data.surv <- df.surv_preds

if (is_transformed == "transformed") {
  data.long <- df.long_censored_transformed
} else {
  data.long <- df.long_censored
}

## Set up for evaluation

# landmark time
T.start <- 2
landmark <- paste0("lm", T.start)
# We can predict on years from (T.start + 1) up to T.max

T.max <- floor(max(data.surv$time)) # Based on last available observation in train set
# [Warning] forsee a potential bug may happen by chance if the longest observation is in test set, but not train

# Predict 15 years onward from landmark time, but not more than max observed time
deltaT <- 1:T.max # A vector of prediction times, starting from baseline onward
deltaT <- deltaT[deltaT > T.start]

# I need to change deltaT later because the notation is inconsistent with the symbol in paper
# the true delta T should be prediction time - landmark time!!!!!!!

print(paste("Evaluation on time since baseline =", paste(deltaT, collapse = " ")))

# Select subjects at risk since landmark time
data.surv <- data.surv %>%
  filter(time > T.start)
data.long <- data.long %>%
  filter(time > T.start)

# Remove the repeated observations after the landmark time
data.long <- data.long %>%
  filter(Years.bl <= T.start)

print(paste("Number of subject at risk after landmark time =", nrow(data.surv)))
print(paste("Number of visits before landmark time (upper bound of measurements) =", nrow(data.long)))



# -----------------------------------------------------------------------------------
# Initialize
# -----------------------------------------------------------------------------------
# Manual exclusion
# Type of TAU, PTAU and ABETA are character, need to handle non-numerical values first. currently excluded
vars_manual_remove <- c("TAU", "PTAU", "ABETA")

# Exclude irrelevant variables
vars_irrelevant <- c(
  names(data.long)[grepl(".bl", names(data.long))], # Exclude baselines, Years.bl, Month.bl
  "RID", "time", "event", "status", "DX",
  "VISCODE", "EXAMDATE", "Y", "M", "Month",
  "AGE", "age.fup", "COLPROT", "ORIGPROT", "PTID", "SITE",
  "PTGENDER", "PTEDUCAT", "PTETHCAT", "PTRACCAT", "PTMARRY", "APOE4",
  "FSVERSION", "IMAGEUID", "FLDSTRENG"
)

vars_ignore <- c(vars_manual_remove, vars_irrelevant) # Variables that will not be considered as long covariates

# Updating the time-varying covariates in data.surv according to landmark time
# For each subject, the latest observed value of time-varying covariate is used
# The value can be transformed or not, depending on data.long assignment

# vars_candidate are the set of candidate long covariates BEFORE screening
vars_candidate <- names(data.surv)[!(names(data.surv) %in% c("id", vars_ignore))]

# -----------------------------------------------------------------------------------
# Update landmark value
# Can it be speed up?
data.surv <- Update_surv_at_landmark(
  surv = data.surv, 
  long = data.long, 
  y.names = vars_candidate)

# -----------------------------------------------------------------------------------
folds <- Initialize_exp(
  data.surv = data.surv,
  data.long = data.long,
  baseline.covs = baseline.covs,
  vars_ignore = vars_ignore,
  set_scenario = set_scenario,
  n_fold = n_fold,
  seed = seed
  )
# Get scaling table
# Note: depends on is_transformed, different set of data.long will be used, hence different scaling factor will be determined

#Check_folds(data.surv, folds) # Checking the split process, stratification

path.template <- paste0("output_folds_template_", set_scenario, "_seed", seed, "_", landmark, "_", is_transformed, ".RData")

save(folds, file = path.template)

print(paste("template of folds saved to path:", path.template))
# -----------------------------------------------------------------------------------
```


# Run glmnet, pencal, mfpccox

