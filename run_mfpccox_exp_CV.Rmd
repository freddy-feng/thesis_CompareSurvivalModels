---
title: "Untitled"
author: "Yibin Feng"
date: '2022-06-09'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Dependencies

```{r}
source("function_utility_exp.R")
source("function_evaluation.R")

source("function_MFPCCox.R") # From Kan Li github
source("function_MFPCCox_exp.R")
```


# Load data
refer to folds template prepared in run_all_exp.rmd

```{r}
rm("folds")
rm("folds.eval")

print(path.template)
load(file = path.template)


# Model param
is_scaled <- "scaled" # Set to "scaled" to scale covariates for LMMs
#is_scaled <- "notScaled" # Set to "scaled" to scale covariates for LMMs
pve <- 0.7 # Hyperparam to choose number of pc
nbasis <- 2
is_transformed <- is_transformed
landmark <- paste0("lm", T.start)

hyperparam <- paste(c(landmark, 
                      is_transformed, 
                      is_scaled, 
                      paste0("pve", as.character(pve*100)), 
                      paste0("nbasis", as.character(nbasis))), 
                    collapse = "_") # Use hyperparam to describe model

print(hyperparam)
```




## MFPCCox - Specify model and temp fix

remove "Fusiform", "Ventricles", "WholeBrain" due to error
Error in .PACE(X = funDataObject@argvals[[1]], funDataObject@X, Y.pred = Y.pred, : 
Measurement error estimated to be zero and there are fewer observed points than PCs; scores cannot be estimated.

```{r}
# variables reported in section 3, MFPCCox paper
# identical over all folds
basecov.names <- folds[[1]]$baseline.covs

# set longitudinal covariates
#y.names.literature <- c("ADAS13", "MMSE", "RAVLT.learning", "RAVLT.immediate", "FAQ") # longitudinal covariates in literature
#y.names # Common to pencal

# Use candidate long covariates as basis, then drop covariates that reported error
# identical over all folds, because the candidate is based on analysis of missing proportions on full data
candidate.long.covs <- folds[[1]]$candidate.long.covs
# [Warning] a temporary fix to remove some covariates 
y.names <- candidate.long.covs[!(candidate.long.covs %in% c("Fusiform", "Ventricles", "WholeBrain", "ICV"))] 
#y.names <- candidate.long.covs

n.y <- length(y.names) # number of long covariates

# time variable for longitudinal variable y
#y.t <- "Years.bl" # timestamp column name for long covariates
#y.t <- "M" # use months from baseline instead of years from baseline, less possible values in obstime
y.t <- "Y" # generic, use years from baseline, rounded

# To prevent a potential bug that the test set has a observed time different from the time domain
# But it also makes it less robust to new data?
obstime <- sort(unique(data.long[, y.t])) # get unique obs timestamp in long data
argvals <- obstime / max(obstime) # scale obstime to [0,1] for uPACE

subject.id <- data.surv$id # subject ids in full data
nPat <- length(subject.id) # number of subjects in full data

# [Temp fix] Manual cleaning in place
# should generalize this step! or fix the root problem!
# or automate the checking and removal process
# df.long_censored_prc.modified <- Remove_invalid_long_data(df.long_censored_prc)
# print(paste("Number of observations in long data before removal =", nrow(df.long_censored_prc)))
# print(paste("Number of observations in long data after removal =", nrow(df.long_censored_prc.modified)))
# 
# long.all <- df.long_censored_prc.modified




```


# Train

At this stage, folds list for cross validation should be initiated.

```{r}
# -----------------------------------------------------------------------------------
# Fit models for each fold
# -----------------------------------------------------------------------------------
for (i in 1:n_fold) {
  print("---------------------------------------------------------------------------------------------------")
  print(paste("Start training in fold", i))
  print("---------------------------------------------------------------------------------------------------")
  # -----------------------------------------------------------------------------------
  # General - Subset subjects for fold i
  # -----------------------------------------------------------------------------------
  tmp <- Get_train_test_data(
    data.surv = data.surv, 
    data.long = data.long,  
    ids.test = folds[[i]]$ids.test, 
    is_scaled = is_scaled, 
    scaling_table = folds[[i]]$scaling_table
  )
  
  training.surv <- tmp$training.surv
  training.long <- tmp$training.long
  
  # -----------------------------------------------------------------------------------  
  # MFPCCox - Initialize multivar array
  # -----------------------------------------------------------------------------------
  # The scaling sould be done within the fold, because the scaling table change on the training data
  if (is_scaled == "scaled") {
    print("[Reminder] scaling is in effect.")
    long.all <- Scale_covariates(data.long, folds[[i]]$scaling_table)
  } else {
    print("[Reminder] no scaling has been done")
    long.all <- data.long
  }
  
  # This multivar array will be shared between train set and test set by indexing
  multivar <- Convert_long_to_mvarray(
    long = long.all, # Full long data, scaled or not scaled
    y.t = y.t,
    obstime = obstime,
    subject_id = subject.id, 
    n_subject = nPat, 
    y.names = y.names, 
    n.y = n.y)
  
  # -----------------------------------------------------------------------------------
  # MFPCCox - fit model
  # -----------------------------------------------------------------------------------
  res <- Train_MFPCCox(
      training.surv = training.surv,
      multivar = multivar, # Converted long data
      subject.id = subject.id, # Vector of subject ids corresponding to multivar
      y.names = y.names, # Candidate long covariates
      argvals = argvals, # Scaled time domain
      pve = pve, # Hyperparam to choose number of pc
      nbasis = nbasis # Number of basis for mean function
      )
  
  # -----------------------------------------------------------------------------------
  # Store results
  # -----------------------------------------------------------------------------------
  folds[[i]]$mfpccox <- list(
    mfpccox = res$mfpccox,
    mfpca.train = res$mfpca.train,
    phi.train = res$phi.train,
    npc.train = res$npc.train,
    runtimes = res$runtimes,
    y.names = y.names,
    subject.id = subject.id, # vector of subject id corresponding to multivar array
    obstime = obstime,
    argvals = argvals,
    multivar = multivar,
    hyperparam = list(
      pve = pve,
      nbasis = nbasis,
      is_scaled = is_scaled
    )
  )
  # -----------------------------------------------------------------------------------
}
# -----------------------------------------------------------------------------------
```



# Test

notes when setting the tstart and deltaT
error occurs in survivalROC when the prediction window gives "sum( unique.t0 <= predict.time )" == 0
solution is to increase deltaT... 
i fail at tstart = 0.5, deltaT = 0.5



[Reminder] requires `multivar` outside the training loop

```{r}
folds.eval <- vector(mode = "list", length = n_fold)

for (i in 1:n_fold) {
  print("---------------------------------------------------------------------------------------------------")
  print(paste("Start testing in fold", i))
  print("---------------------------------------------------------------------------------------------------")
  # -----------------------------------------------------------------------------------
  # General - Subset subjects for fold i
  # -----------------------------------------------------------------------------------
  tmp <- Get_train_test_data(
    data.surv = data.surv, 
    data.long = data.long,  
    ids.test = folds[[i]]$ids.test, 
    is_scaled = is_scaled, 
    scaling_table = folds[[i]]$scaling_table
  )
  
  training.surv <- tmp$training.surv
  
  surv.new <- tmp$testing.surv
  long.new <- tmp$testing.long
  
#  print(paste("[Count] subject at risk at landmark", length(ids.at_risk)))
  
  # -----------------------------------------------------------------------------------
  # MFPCCox specific landmarking process
  # -----------------------------------------------------------------------------------
  # -----------------------------------------------------------------------------------
  # Subset test data from multivar array
  is_test <- folds[[i]]$mfpccox$subject.id %in% surv.new$id # Get subjects at-risk that are event-free at landmark time, t  
  tmp.data <- multivar[is_test, , ] # subset longitudinal outcomes for test set
  

  # Need multivar.train for fold i in UFPCA step
  is_train <- folds[[i]]$mfpccox$subject.id %in% training.surv$id # Get (row indices of) subjects in train set
  multivar.train <- multivar[is_train, , ] # Subset for train set
  
  # -----------------------------------------------------------------------------------  
  # MFPCCox - Evaluate model
  # ----------------------------------------------------------------------------------- 
  # -----------------------------------------------------------------------------------  
  # MFPCCox - uFPCA
  # ----------------------------------------------------------------------------------- 
  # univariate FPC 
  Xi.test <- NULL # Xi: FPC scores
  
  for(p in 1:n.y){ # for each longitudinal covariate
    
    # Retreive information from trained models
#    pve.trained <- folds[[i]]$mfpccox$hyperparam$pve 
    nbasis.trained <- folds[[i]]$mfpccox$hyperparam$nbasis
    
    print(paste("Computing score for ", folds[[i]]$mfpccox$y.names[[p]]))
    
    npc.trained <- folds[[i]]$mfpccox$npc.train[[p]]
    
    # estimated trajectories based on a truncated Karhunen-Loeve representation on pred data
    tmp.ufpca <- uPACE(
      testData = multivar.train[, , p], # Specific to train set in each fold
      domain = folds[[i]]$mfpccox$argvals, # Should be set of constant
      predData = tmp.data[, , p], 
      nbasis = nbasis.trained,
      #pve = pve.trained,
      npc = npc.trained)
    
    Xi.test <- cbind(Xi.test, tmp.ufpca$scores) # dynamic FPC scores for test subjects 
  }
  # -----------------------------------------------------------------------------------  
  # MFPCCox - MFPCA
  # ----------------------------------------------------------------------------------- 
  # estimate MFPC scores for test subjects
  rho.test <- mfpca.score(Xi.test, folds[[i]]$mfpccox$mfpca$Cms)
  #tmp.surv.data$rho <- rho.test  
  # -----------------------------------------------------------------------------------
  # Compute the linear predictor
  tmp.rho <- data.frame(rho.test)
  rho.names <- paste0("rho", 1:ncol(rho.test))
  names(tmp.rho) <- rho.names
  tmp.surv.data <- data.frame(surv.new, tmp.rho)
  
  X.orig <- tmp.surv.data %>%
    select(all_of(basecov.names), all_of(rho.names))
  
  linpred <- predict(
    object = folds[[i]]$mfpccox$mfpccox, # Fitted "coxph" object
    newdata = X.orig, # new values for x at which predictions are to be made
    type = "lp" # Type "link" (default) returns x^T \beta
    )

  
  # -----------------------------------------------------------------------------------
  # General - Compute tdROC and tdAUC, c-index
  # -----------------------------------------------------------------------------------
  res.tdauc <- Evaluate_tdauc(surv.new, linpred, T.start, deltaT)
  res.c.naive <- survcomp::concordance.index(
    x = linpred, # vector of risk predictions
    surv.time = surv.new$time, # vector of event times
    surv.event = surv.new$event, # vector of event occurence indicators
    method = "noether" # conservative, noether or name (see paper Pencina et al. for details)
    )
  # -----------------------------------------------------------------------------------
  
  # -----------------------------------------------------------------------------------
  # Store results
  # -----------------------------------------------------------------------------------
#  folds.eval[[i]]$ids.test_no_missing <- ids.valid
  folds.eval[[i]]$perf <- list(
    landmark = T.start,
    deltaT = deltaT,
    c.index = res.c.naive$c.index,
    tdauc = res.tdauc$tdauc,
    tp = res.tdauc$tp,
    fp = res.tdauc$fp
  )
  # -----------------------------------------------------------------------------------
}

```






```{r}
print("cv.c-index")
# Estimated C-index
cv.c.index <- sapply(folds.eval, function(x) x$perf$c.index)
mean(cv.c.index) %>% round(3)
sd(cv.c.index) %>% round(3)
```

```{r}
# Estimated tdAUC for deltaT
cv.tdauc <- data.frame(
  deltaT = folds.eval[[1]]$perf$deltaT,
  tdauc.fold = sapply(folds.eval, function(x) x$perf$tdauc) # row is fold, column is prediction window
)

# Plot figure for average tdauc in single CV
cv.tdauc %>%
  mutate(mean = rowMeans(across(starts_with("tdauc")))) %>%
  select(deltaT, mean) %>%
  round(3) %>%
  ggplot() + 
    geom_point(aes(x = deltaT, y = mean)) +
    geom_line(aes(x = deltaT, y = mean)) +
    scale_y_continuous(breaks = 0:10 / 10) +
    coord_cartesian(ylim = c(0, 1)) +
    xlab("Time since baseline") + ylab("cv tdAUC")

```

```{r, fig.width=15, fig.height=9}
g <- Plot_all_tdROC(folds.eval)

g
```

# Save 

```{r}
# Save evaluation result
tmp <- paste0("./output/eval_", set_scenario, "_MFPCCox_", hyperparam, "_seed", seed, ".RData")
save(folds.eval, file = tmp)
print(paste("folds.eval saved to path:", tmp))
```

```{r}
# [Optional] save model
tmp <- paste0("./model/model_", set_scenario, "_MFPCCox_", hyperparam, "_seed", seed, ".RData")
save(folds, file = tmp)

print(paste("Trainined models in folds saved to path:", tmp))
```
