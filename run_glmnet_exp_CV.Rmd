---
title: "Untitled"
author: "Yibin Feng"
date: '2022-06-09'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r}
source("function_utility.R")
source("function_evaluation.R")

source("function_glmnet_exp.R")

```


# Load data
refer to folds template prepared in run_all_exp.rmd

```{r}
# -----------------------------------------------------------------------------------
# Set model param
is_scaled <- is_scaled # Set to "scaled" to scale covariates for LMMs
is_transformed <- is_transformed
landmark <- paste0("lm", T.start)
n_basecov <- paste0("b", length(baseline.covs))
glmnet.alpha <- 0 # 0 for ridge, 1 for lasso

penality.type <- if (glmnet.alpha == 0) {
    "ridge"
  } else if (glmnet.alpha == 1) {
    "lasso"
  } else {
    "elasticnet"
  }

model.hyperparam <- list(
  method = method,
  set_scenario = set_scenario,
  landmark = landmark,
  is_scaled = is_scaled,
  is_transformed = is_transformed,
  glmnet.alpha = glmnet.alpha
)

hyperparam <- paste(c(set_scenario, n_basecov, is_transformed, is_scaled, penality.type), collapse = "_") # Use hyperparam to describe model
model.name <- paste(c(method, landmark, hyperparam), collapse = "_")

print(paste("Begin training for model:", model.name))
# -----------------------------------------------------------------------------------
```


# Train

At this stage, folds list for cross validation should be initiated.

```{r}
# -----------------------------------------------------------------------------------
rm("folds")
rm("folds.eval")

print(path.template)
load(file = path.template) # Load folds template
# -----------------------------------------------------------------------------------
# Fit models for each fold
# -----------------------------------------------------------------------------------
for (i in 1:n_fold) {
  print("---------------------------------------------------------------------------------------------------")
  print(paste("Start training in fold", i))
  print("---------------------------------------------------------------------------------------------------")
  # -----------------------------------------------------------------------------------
  # General - Subset subjects for fold i
  # -----------------------------------------------------------------------------------
  tmp <- Get_train_test_data(
    data.surv = data.surv, 
    data.long = data.long,  
    ids.test = folds[[i]]$ids.test, 
    is_scaled = is_scaled, 
    scaling_table = folds[[i]]$scaling_table
  )
  
  training.surv <- tmp$training.surv
  training.long <- tmp$training.long
  
  # -----------------------------------------------------------------------------------
  # pCox - train model
  # -----------------------------------------------------------------------------------
  # Baseline covariates used for fitting penalized Cox model in all folds
  baseline.covs <- folds[[i]]$baseline.covs
  baseline.covs.additional <- folds[[i]]$candidate.long.covs
  
  scenario <- folds[[i]]$scenario # Deciding number candidate covariates used

  # Note: imputation inside
  res <- Train_glmnet(
    training.surv = training.surv,
    training.long = training.long,
    scenario = scenario,
    baseline.covs = baseline.covs,
    baseline.covs.additional = baseline.covs.additional,
    glmnet.alpha = glmnet.alpha
  )
  
  # -----------------------------------------------------------------------------------
  # Store results
  # -----------------------------------------------------------------------------------
  folds[[i]]$model <- list(
    name = model.name,
    hyperparam = model.hyperparam,
    covariate = list(
      base = res$covs.pcox),
    cvfit = res$cvfit,
    training.time = res$runtimes
  )
}
# -----------------------------------------------------------------------------------
```




# Test


```{r}
# -----------------------------------------------------------------------------------
# Test
folds.eval <- vector(mode = "list", length = n_fold)

for (i in 1:n_fold) {
  # -----------------------------------------------------------------------------------
  # General - Subset subjects for fold i
  # -----------------------------------------------------------------------------------
  tmp <- Get_train_test_data(
    data.surv = data.surv, 
    data.long = data.long,  
    ids.test = folds[[i]]$ids.test, 
    is_scaled = is_scaled, 
    scaling_table = folds[[i]]$scaling_table
  )
  
  surv.new <- tmp$testing.surv
  long.new <- tmp$testing.long

  # -----------------------------------------------------------------------------------  
  # pCox - Evaluate model
  # ----------------------------------------------------------------------------------- 
  # Step 1 - prepare new X
  # Subset columns to construct model matrix on new data
  covs.pcox <- folds[[i]]$model$covariate$base
  testing.x.covs <- surv.new %>%
    select(all_of(covs.pcox))
  
  # Mean imputation based on test data
  # No information leakage
  testing.x.covs.imputed <- Imputate.x.mean(testing.x.covs)
  # Convert data to model matrix
  testing.x.mat <- model.matrix(~ ., data = testing.x.covs.imputed)
  # Observed response
  testing.y <- survival::Surv(
    time = surv.new$time,
    event = surv.new$event,
    type = "right"
  )
  # Step 2 - compute linear predictor
  linpred <- predict(
    folds[[i]]$model$cvfit, # Fitted "cv.glmnet" object
    newx = testing.x.mat, # Matrix of new values for x at which predictions are to be made. Must be a matrix
    s = "lambda.min",
    type = "link" # Type "link" (default) returns x^T \beta
    )
  
  # -----------------------------------------------------------------------------------
  # General - Compute tdROC and tdAUC, c-index
  # -----------------------------------------------------------------------------------
  res.tdauc <- Evaluate_tdauc(surv.new, linpred, T.start, deltaT)
  res.c.index <- survcomp::concordance.index(
    x = linpred, # vector of risk predictions
    surv.time = surv.new$time, # vector of event times
    surv.event = surv.new$event, # vector of event occurence indicators
    method = "noether" # conservative, noether or name (see paper Pencina et al. for details)
    )
  # -----------------------------------------------------------------------------------
  
  # -----------------------------------------------------------------------------------
  # Store results
  # -----------------------------------------------------------------------------------
  # Performance
  folds.eval[[i]]$perf <- list(
    landmark = T.start,
    deltaT = deltaT,
    c.index = res.c.index$c.index,
    tdauc = res.tdauc$tdauc,
    tp = res.tdauc$tp,
    fp = res.tdauc$fp)
  # Carry over model information in case training model is not kept
  folds.eval[[i]]$model.info <- list(
      name = folds[[i]]$model$name,
      hyperparam = folds[[i]]$model$hyperparam,
      covariate = folds[[i]]$model$covariate,
      training.time = folds[[i]]$model$training.time
    )
  # -----------------------------------------------------------------------------------
}
```


```{r, eval=FALSE}
library(pec)

res.survpred <- summary(
  survfit(
    folds[[i]]$model$cvfit, 
    x = training.x.mat, y = training.y, 
    s = "lambda.min", 
    newx = testing.x.mat),
  times = 0:15)

test.brier <- pec(
  object = list("test" = t(res.survpred$surv)), # A matrix with predicted probabilities, dimension of n subjects by m times 
  formula = Surv(time, event) ~ AGE, # Survival formula for censoring model
  data = surv.new, # Data frame in which to validate the prediction models and to fit the censoring model
  exact = FALSE, # Do not predict at event times
  times = 0:15, # Predict at given times
  cens.model = "cox", # Method for estimating inverse probability of censoring weights:
  # cox: A semi-parametric Cox proportional hazard model is fitted to the censoring times
  # marginal: The Kaplan-Meier estimator for the censoring times
  splitMethod = "none", # SplitMethod for estimating the prediction error curves
  B = 0, # Number of bootstrap samples. The default depends on argument splitMethod.
  verbose = TRUE # if TRUE report details of the progress, e.g. count the steps in cross-validation.
  )


# Does not work! It does not contain the baseline survival function => surv prob is not known
# predsurvprob <- predict(
#   folds[[i]]$model$cvfit, # Fitted "cv.glmnet" object
#   newx = testing.x.mat, # Matrix of new values for x at which predictions are to be made. Must be a matrix
#   s = "lambda.min",
#   type = "response" # Type "link" (default) returns x^T \beta
#   )

```


# Inpsect results

```{r}
print("Print c-index in CV")
cv.c.index <- sapply(folds.eval, function(x) x$perf$c.index)
mean(cv.c.index) %>% round(3)
sd(cv.c.index) %>% round(3)
```

```{r}
i <- 1

# Estimated tdAUC for deltaT
cv.tdauc <- data.frame(
  deltaT = folds.eval[[i]]$perf$deltaT,
  tdauc.fold = sapply(folds.eval, function(x) x$perf$tdauc) # row is fold, column is prediction window
)

# Plot figure for average tdauc in single CV
cv.tdauc %>%
  mutate(mean = rowMeans(across(starts_with("tdauc")))) %>%
  select(deltaT, mean) %>%
  round(3) %>%
  ggplot() + 
    geom_point(aes(x = deltaT, y = mean)) +
    geom_line(aes(x = deltaT, y = mean)) +
    scale_x_continuous(breaks = deltaT) +
    scale_y_continuous(breaks = 0:10 / 10) +
    coord_cartesian(ylim = c(0, 1)) +
    xlab("Time since baseline") + ylab("cv tdAUC")

```


```{r, fig.width=15, fig.height=9, eval=FALSE}
g <- Plot_all_tdROC(folds.eval)

g
```

# Save


```{r}
# Save evaluation result
folder <- "./output/eval_"
path.eval <- paste0(folder, model.name, "_seed", seed, ".RData")

save(folds.eval, file = path.eval)
print(paste("Performance in folds saved:", path.eval))
```

```{r, eval=FALSE}
# [Optional] save model
folder <- "./model/model_"
path.model <- paste0(folder, model.name, "_seed", seed, ".RData")

save(folds, file = path.model)
print(paste("Models in folds saved:", path.model))

```

